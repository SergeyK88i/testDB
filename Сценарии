Финальный мастер-шаблон (версия с полными подсказками)

  1. Идентификация и Цель
   * Ключевые вопросы:
       * Какую бизнес-проблему мы решаем?
       * Какая система является источником данных?
       * Какие данные нам нужны на концептуальном уровне?
       * С кем со стороны источника велось общение? (контакт для технических вопросов)

  2. Инфраструктура и Окружение

   * 2.1. Сетевое взаимодействие (Маршрут и Доступы)
       * Ключевые вопросы:
           * Документация архитектуры: Отражена ли интеграция в официальной архитектурной схеме проекта?
           * Местоположение: В каких сегментах сети находятся наш сервис и целевая система?
           * Маршрут и Точка подключения: Исходя из местоположения, каким будет маршрут (прямой, через proxy/gateway)? Каким будет итоговый
             адрес для подключения нашего сервиса?
           * Процесс согласования: Требуется ли формальное согласование этого сетевого взаимодействия (например, с отделом ИБ)?
           * Запрос на доступ: Если да, что именно нужно указать в заявке на открытие доступов (IP источника, IP назначения, порт)?

   * 2.2. Тестовые среды
       * Ключевые вопросы:
           * Есть ли у источника тестовый контур? Каковы его реквизиты и ограничения?

   * 2.3. Готовность на PROD
       * Ключевые вопросы:
           * Нужный функционал выведен и стабильно работает в PROD-среде источника если нет заведен  CR ссылку на CR?

  3. Доступ к Источнику (Прикладной уровень)

   * 3.1. Технология и паттерн интеграции
       * Ключевые вопросы:
           * Какая технология и паттерн используются (e.g., REST, gRPC, Kafka, DB Connection)?

   * 3.2. Реквизиты для подключения (Адреса и Аутентификация)
       * Ключевые вопросы (адаптируются под п. 3.1):
           * Каковы адреса/эндпоинты для подключения?
           * Какой механизм аутентификации используется?
           * Какие конкретно креды/ключи/сертификаты нужны?
       * Подсказка/Примеры:
           * Адреса:
               * Для REST: https://api.some-service.com/v1/
               * Для Kafka: kafka1.corp.local:9092
               * Для БД: postgres-db.prod.local:5432
           * Механизмы аутентификации:
               * Bearer Token, API Key, Basic Auth, mTLS, SASL/SCRAM, AD ТУЗ (Kerberos/NTLM)
           * Креды/ключи (конкретные секреты):
               * Для API Key: ABC-123-XYZ-456
               * Для mTLS: Указание на файлы client.crt, client.key и их Common Name (CN).
               * Для AD ТУЗ: Пара логин/пароль. Например: login: srv_myapp_prod, password: (хранится в vault).

   * 3.3. Процесс получения доступа (Бюрократия)
       * Ключевые вопросы:
           * Есть ли документация, описывающая процесс получения доступа? (e.g., статья в Confluence, регламент)
           * Каковы точные шаги для получения кредов/ключей/сертификатов, описанных в п. 3.2? (e.g., "Подать заявку в Service Desk по шаблону
             X")

  4. Логика Работы с Данными
   * Ключевые вопросы:
       * Где находится документация на API / формат сообщений?
       * Какой эндпоинт/топик/таблицу мы используем?
       * Какие параметры запроса нужно передавать / как фильтровать сообщения?
       * Какие поля из ответа/сообщения нам нужны и какую логику к ним применить?
       * Каков финальный результат вычисления?

  5. Ускорение Разработки и Критерии Успеха
   * Ключевые вопросы:
       * Как выглядят примеры ответов/сообщений (успех, ошибка, пустой ответ)?
       * Как мы однозначно поймем, что задача выполнена корректно?

  Обновленный раздел 6

  6. Эксплуатация и Ограничения

   * 6.1. Ограничения на стороне источника
       * Ключевые вопросы:
           * Есть ли ограничения на частоту запросов (rate limits)?
           * Какой должна быть наша стратегия повторных запросов (retry policy)?

   * 6.2. Метрики и Аудит
       * Ключевые вопросы:
           * Технические метрики: Какие технические метрики нужно собирать для мониторинга здоровья интеграции? (e.g., количество 
             успехов/ошибок, время выполнения)
           * Данные для аудита: Какие данные о результате вычисления и "доказательства" нужно сохранять для последующего аудита и разбора?
             (e.g., "Сохранять итоговый балл, ID проверенной страницы в Confluence, время проверки")

  ---

  Пример заполнения для нового пункта 6.2

   * Технические метрики:
       * счетчик успешных проверок по критерию
       * счетчик ошибок по критерию и типу (сетевая, ошибка парсинга, нет данных)
       * гистограмма длительности выполнения проверки (latency)
   * Данные для аудита:
       * ID источника
       * ID критерия
       * итоговый балл
       * время проверки (timestamp)
       * ключевое "доказательство" (например, ID найденной страницы в Confluence или конкретное значение, полученное из API, которое повлияло 
         на решение)

1. Технические метрики (для инженеров)

  Цель: Следить за "здоровьем" и производительностью интеграции в реальном времени. Отвечают на вопрос: "Все ли работает как надо?". Эти
  данные обычно отправляются в системы мониторинга (например, Prometheus, Grafana).

   * `счетчик успешных проверок по критерию`
       * Что это: Простая цифра, которая увеличивается на 1 каждый раз, когда мы успешно рассчитали один критерий для одного источника.
       * Зачем это нужно: Если мы видим, что этот счетчик перестал расти, значит, наш процесс сломался или остановился. Мы можем настроить
         алерт: "Если за час не было ни одной успешной проверки, прислать уведомление в #alerts".

   * `счетчик ошибок по критерию и типу (сетевая, ошибка парсинга, нет данных)`
       * Что это: Счетчик, который срабатывает при ошибке. Важно, что мы помечаем его "типом" ошибки.
       * Зачем это нужно: Это главный инструмент для диагностики.
           * Резко вырос счетчик сетевых ошибок? Значит, проблема со связью до системы-источника, нужно проверить сеть.
           * Растет счетчик ошибок парсинга? Значит, источник мог поменять формат ответа своего API, и нам нужно адаптировать наш код.
           * Растет счетчик "нет данных"? Значит, интеграция работает, но мы не находим нужную информацию, возможно, ее удалили или
             переместили.

   * `гистограмма длительности выполнения проверки (latency)`
       * Что это: Метрика, которая измеряет, сколько миллисекунд или секунд уходит на одну проверку. Гистограмма позволяет видеть не просто
         среднее время, а распределение (e.g., 90% запросов выполняются за 200мс, а 10% — за 2 секунды).
       * Зачем это нужно: Для отслеживания производительности. Если мы видим, что время проверки постепенно растет, это сигнал, что
         система-источник стала медленнее или наш алгоритм неэффективен. Это помогает обеспечивать соблюдение нефункциональных требований
         ("система должна быть быстрой").

  ---

  2. Данные для аудита (для бизнес-пользователей и владельцев источников)

  Цель: Обеспечить полную прозрачность и доказуемость расчетов. Отвечают на вопрос: "Почему для этого источника получился именно такой
  балл?". Эти данные обычно сохраняются в базу данных или лог-файлы на длительный срок.

   * `ID источника`, `ID критерия`, `итоговый балл`, `время проверки (timestamp)`
       * Что это: Базовая информация: кто, что проверяли, какой результат получили и когда.
       * Зачем это нужно: Это основа для любого отчета или расследования. Позволяет делать запросы вроде "Покажи все расчеты для 'Источника А'
         за последний месяц".

   * `ключевое "доказательство"`
       * Что это: Это самая важная часть для аудита. Это конкретная улика или факт, на основе которого был сделан вывод.
       * Зачем это нужно: Это ответ на вопрос "На каком основании?".
           * Пример 1: Критерий — "Наличие документации в Confluence". Расчет успешен, балл = 10. "Доказательством" будет page_id=54321
             найденной страницы. Если владелец источника спросит "Почему 10?", мы ответим: "Потому что мы нашли вот эту страницу: [ссылка]".
           * Пример 2: Критерий — "Отсутствие критичных инцидентов". Расчет провален, балл = 0. "Доказательством" будет incident_id='INC-98765'
             найденного инцидента. Мы можем сказать: "Балл снижен из-за этого конкретного инцидента, разберитесь с ним".


-------------------
Цель мониторинга — в реальном времени, с помощью дашбордов (в Grafana), понимать, что происходит с вашей системой. Это приборная панель
  вашего сервиса.

  Принято использовать стандартный набор метрик, который описывает три ключевых аспекта работы любого сервиса (метод RED: Rate, Errors,
  Duration).

  Вот что должно быть в вашем мониторинге для каждой интеграции:

  ---

  1. Rate (Интенсивность) — "Как часто мы это делаем?"

  Эта метрика показывает нагрузку на вашу систему.

   * Название метрики: integration_runs_total
   * Тип: Counter (счетчик, который только увеличивается)
   * Зачем нужна:
       * Показывает, сколько всего проверок было запущено.
       * Если график rate(integration_runs_total[5m]) (скорость запусков за 5 минут) падает до нуля, это значит, что ваш сервис перестал
         запускать проверки. Это повод для алерта.
       * Резкий всплеск может говорить о том, что проверки запускаются по ошибке слишком часто.
   * Важные метки/лейблы: criterion_id (чтобы видеть интенсивность по каждому критерию отдельно).

  2. Errors (Ошибки) — "Как много у нас проблем?"

  Это самая важная метрика для оценки здоровья системы.

   * Название метрики: integration_errors_total
   * Тип: Counter
   * Зачем нужна:
       * Показывает общее количество ошибок. Если это число начинает расти — это главный сигнал о проблеме и повод для срочного алерта.
       * Позволяет считать уровень ошибок (Error Rate) = количество ошибок / общее количество запусков.
   * Важные метки/лейблы:
       * criterion_id: Позволяет понять, какой именно критерий "сломался".
       * error_type: Критически важная метка для диагностики. Значения могут быть:
           * network: Не удалось подключиться к источнику.
           * auth: Ошибка аутентификации (неверный токен, пароль).
           * parsing: Не удалось разобрать ответ от API (источник поменял формат).
           * business_logic: Ошибка в нашей внутренней логике расчета.

  Как это используется: На дашборде в Grafana вы строите график скорости роста ошибок, сгруппированный по error_type. Если вы видите всплеск
  ошибок типа auth для критерия C-05, вы точно знаете, что у вас, скорее всего, "протух" токен для этой конкретной интеграции.

  3. Duration (Длительность) — "Как быстро мы работаем?"

  Эта метрика отслеживает производительность и "тормоза".

   * Название метрики: integration_duration_seconds
   * Тип: Histogram или Summary
   * Зачем нужна:
       * Показывает, сколько времени занимает расчет одного критерия.
       * Помогает отслеживать деградацию производительности. Если среднее время или 99-й перцентиль (самые медленные запросы) начинают расти,
         это значит, что либо источник стал медленнее отвечать, либо наш код стал менее эффективным.
       * Позволяет настроить алерт: "Если 95-й перцентиль времени ответа больше 5 секунд, прислать уведомление".
   * Важные метки/лейблы: criterion_id.

  ---

  Итог для дашборда

  Имея эти три типа метрик, вы можете создать в Grafana полный дашборд для мониторинга ваших интеграций, где по каждому критерию будет видно:
   1. График интенсивности запусков.
   2. График количества и типа ошибок.
   3. График времени выполнения (среднее и 99-й перцентиль).

  Это позволяет вам перейти от реактивного подхода ("пользователь сообщил о проблеме") к проактивному ("наш дашборд показывает аномалию,
  давайте исправим ее до того, как пользователи это заметят").

=============================================================

Да, вы можете начать декомпозицию и разработку раньше. Для этого нужно разделить наш шаблон на два блока: абсолютный минимум для старта и
  все остальное, что можно получить параллельно.

  ---

  Блок 1: Абсолютный минимум для старта разработки (пишем код на моках)

  Это тот набор информации, без которого разработчик в принципе не может начать писать код, даже в изоляции от реальной системы. Как только
  аналитик заполнил эти пункты, техлид может создавать первые задачи.

  Супер обязательные пункты:

   1. Раздел 1. Идентификация и Цель (полностью): Нужно понимать бизнес-задачу.
   2. Пункт 3.1. Технология и паттерн интеграции: Принципиально важно знать, это REST или Kafka, так как от этого зависит вся архитектура кода.
   3. Раздел 4. Логика Работы с Данными (частично, но критично):
       * Структура данных: Какие поля есть в ответе/сообщении.
       * Основная логика: Что с этими полями делать.
       * Ссылка на документацию может подождать, если есть примеры.
   4. Пункт 5. Ускорение Разработки (только примеры ответов/сообщений): Это ключ к параллельной разработке. Имея на руках пример JSON-ответа,
      разработчик может создать классы, написать логику и полностью покрыть ее юнит-тестами, не имея реального доступа к системе.

  Что можно делать с этим блоком?
  Как только эти пункты заполнены, техлид может ставить задачи вида:
   * "Создать модель данных (DTO) для ответа от Системы Х".
   * "Реализовать сервис для обработки данных от Системы Х (на входе мок, на выходе результат)".
   * "Написать юнит-тесты для сервиса обработки".

  ---

  Блок 2: Необходимо для реального подключения и вывода в PROD (заполняется параллельно)

  Эти пункты не блокируют написание основной бизнес-логики, но абсолютно необходимы для того, чтобы интеграция заработала по-настоящему.
  Аналитик может продолжать "добывать" эту информацию, пока разработчики пишут код на основе данных из Блока 1.

  Пункты, которые могут подождать (но их получение нужно запустить как можно раньше):

   1. Раздел 2. Инфраструктура и Окружение (полностью): Все вопросы про сеть, доступы, стенды. Это часто самые долгие процессы, их нужно
      запускать в параллель.
   2. Раздел 3 (кроме п. 3.1): Все, что касается реальных адресов, реквизитов и бюрократии по получению доступов.
   3. Раздел 6. Эксплуатация и Ограничения (полностью): Ретраи, метрики, лимиты. Эту "обвязку" можно добавить к уже написанному коду основной
      логики.
   4. Критерии успеха из Раздела 5: Их можно финализировать чуть позже.

  Итог: Стратегия параллельной работы

   1. Аналитик в первую очередь фокусируется на получении информации для Блока 1.
   2. Как только Блок 1 готов, он передает его техлиду. Разработка начинается.
   3. Параллельно аналитик (или техлид) запускает все процессы по получению информации и доступов для Блока 2 (подает заявки в ИБ, запрашивает
      креды и т.д.).
   4. Когда разработчик заканчивает код на моках, в идеале, доступы из Блока 2 уже получены. Остается только подставить реальные адреса и креды,
      дописать логику обработки ошибок, ретраев, метрик и провести интеграционное тестирование.

===========
Оптимизированный процесс (более гибкий)

   1. Идея (Эпик от ПО).
   2. Встреча №1: Kick-off. ПО объясняет цель команде.
   3. Анализ. Аналитик работает над шаблоном, но не в изоляции, а по нашей "Инструкции" (т.е. проводит рабочую встречу с командой источника).
   4. Встреча №2 (расширенная): Воркшоп по аналитике и декомпозиции. (Объединяем ваши встречи №2 и №3)
       * Часть 1 (15-20 мин): Аналитик презентует команде заполненный шаблон. Все задают вопросы.
       * Часть 2 (30-40 мин): Техлид и разработчики сразу же, на этой же встрече, накидывают и обсуждают основные задачи в Jira. Это
         превращается в сессию груминга/планирования бэклога.
   5. Разработка (включая Unit/интеграционные тесты). Разработчики пишут код и тесты к нему.
   6. Тестирование (QA). QA-инженер проводит E2E и исследовательское тестирование.
   7. ПСИ.
   8. Релиз на PROD.
============
Информация для первоначального анализа и настройки:

   1. Контактное лицо: Получить имя и контакты технического специалиста, который будет отвечать на вопросы.

   2. Документация: Получить ссылки на всю релевантную документацию:
       * Описание API или формата сообщений.
       * Инструкции по получению доступов.

   3. Подтверждение по инфраструктуре: Получить ответы на вопросы:
       * О сетевой архитектуре.
       * О наличии или отсутствии тестовых стендов.
       * О готовности функционала в PROD-среде.

   4. Подтверждение процесса доступа: Узнать и зафиксировать точные шаги, которые нужно будет предпринять для получения доступов (как для сети,
      так и для приложения).

   5. Технические детали подключения: Узнать:
       * Точные адреса/эндпоинты/bootstrap-серверы.
       * Используемый механизм аутентификации.
       * Информацию об ограничениях (rate limits) и рекомендуемой политике повторных запросов (retry policy).

   6. Примеры данных (моки): Получить примеры реальных ответов API или сообщений для разных сценариев (успех, ошибка, пустой ответ).

==============
Шаблон спецификации для новой фичи

  1. Общая информация

   * Название фичи: (Краткое, понятное название, e.g., "Экран модерации расчетов ИЗИ")
   * Ссылка на эпик в Jira: (Ссылка на родительскую задачу)
   * Проблема / Бизнес-цель: (Описать, какую проблему пользователя или бизнеса мы решаем. ЗАЧЕМ мы это делаем? E.g., "Модераторы тратят много
     времени на проверку расчетов, так как у них нет единого интерфейса для просмотра и утверждения. Цель — ускорить процесс модерации в 3
     раза.")
   * Пользовательские роли: (Для КОГО эта фича? E.g., "Модератор", "Администратор")

  2. Функциональные требования в формате User Stories

  (Это основной раздел, описывающий, ЧТО должна делать фича. Лучше всего разбить большую фичу на несколько маленьких историй.)

   * User Story 1: Просмотр списка расчетов
       * Как Модератор, я хочу видеть на экране список всех расчетов, ожидающих модерации, чтобы я мог быстро оценить объем работы.
   * User Story 2: Фильтрация списка
       * Как Модератор, я хочу иметь возможность фильтровать список расчетов по источнику и дате, чтобы я мог найти конкретный расчет.
   * User Story 3: Утверждение/отклонение расчета
       * Как Модератор, я хочу иметь возможность нажать кнопки "Утвердить" или "Отклонить" для каждого расчета, чтобы я мог завершить процесс
         модерации.

  3. Требования к UI/UX (Пользовательский интерфейс)

  (Этот раздел отвечает на вопрос, КАК это должно выглядеть. Он не требует от аналитика быть дизайнером, но требует описать основные
  элементы.)

   * Расположение в интерфейсе: (Где пользователь найдет эту фичу? E.g., "Новый пункт меню 'Модерация' в левой боковой панели.")
   * Основные элементы экрана: (Что пользователь увидит на странице?)
       * Таблица с расчетами. Колонки: ID Источника, Дата расчета, Итоговый балл, Статус.
       * Блок с фильтрами над таблицей: выпадающий список Источник, поле для выбора Даты.
       * В каждой строке таблицы — кнопки Утвердить и Отклонить.
   * Ссылка на макеты/прототипы: (Критически важный пункт!) Ссылка на дизайн в Figma, Balsamiq или даже просто скриншот с нарисованными от руки
     элементами.

  4. Бизнес-логика и правила валидации

  (Здесь описываются конкретные правила и условия.)

   * Кнопка "Утвердить" активна только для расчетов в статусе "Ожидает модерации".
   * При отклонении расчета должно появляться модальное окно с обязательным полем для ввода причины отклонения.
   * Пользователи с ролью "Администратор" видят все расчеты, а "Модератор" — только те, что назначены на его отдел.

  5. Пограничные случаи и обработка ошибок

  (Что будет, если что-то пойдет не так или данных нет?)

   * Пустое состояние: Что показывать, если список расчетов на модерацию пуст? (e.g., "Показывать текст 'Расчетов для модерации нет' и
     картинку.")
   * Ошибка загрузки: Что делать, если не удалось загрузить список с сервера? (e.g., "Показать сообщение об ошибке 'Не удалось загрузить
     данные' и кнопку 'Попробовать снова'.")

  6. Критерии приемки (Acceptance Criteria)

  (Как мы поймем, что фича работает правильно? Формат GIVEN-WHEN-THEN идеален для QA.)

   * Сценарий 1: Успешное утверждение
       * GIVEN: Модератор находится на экране модерации и видит расчет со статусом "Ожидает модерации".
       * WHEN: Он нажимает кнопку "Утвердить".
       * THEN: Статус расчета меняется на "Утвержден", и он пропадает из списка.
   * Сценарий 2: Отклонение с причиной
       * GIVEN: Модератор нажимает кнопку "Отклонить".
       * WHEN: Он вводит причину в модальном окне и нажимает "Подтвердить".
       * THEN: Статус расчета меняется на "Отклонен", и он пропадает из списка.

  7. Нефункциональные требования

  (Требования к качеству, безопасности, производительности.)

   * Производительность: Список расчетов должен загружаться не дольше 2 секунд.
   * Безопасность: Доступ к этому экрану должен быть только у ролей "Модератор" и "Администратор".
   * Аудит: Каждое действие (утверждение, отклонение) должно записываться в журнал аудита с указанием, какой модератор и когда это сделал.
=====================
Роль аналитика здесь вырастает до системного аналитика или архитектора. Его первая задача — не детализация, а декомпозиция самого проекта.
  Он не использует другой шаблон, а создает новый, высокоуровневый документ, который можно назвать "Дорожная карта проекта" или
  "Архитектурное видение".

  Цель этого документа — разбить гигантскую задачу "внедрить Auth" на понятные, управляемые части (эпики), к каждой из которых потом уже 
  можно будет применить наши существующие шаблоны.

  Вот как может выглядеть структура такого документа:

  ---

  Шаблон: Дорожная карта проекта "Внедрение системы Auth"

  1. Цели и Область применения (Scope)
   * Бизнес-цели: Зачем мы это делаем? (e.g., "Повысить безопасность", "Упростить управление доступами", "Ввести единую точку входа (SSO)").
   * В Scope: Что входит в рамки проекта? (e.g., "Новый сервис аутентификации, интеграция с корпоративным AD, миграция 3-х ключевых
     приложений").
   * Вне Scope: Что мы НЕ делаем? (e.g., "Миграция всех 100+ приложений компании", "Управление правами внутри самих приложений").

  2. Архитектура верхнего уровня
   * Простая диаграмма, показывающая, как новый сервис Auth будет взаимодействовать с другими системами: пользователями, вашими приложениями,
     базой данных пользователей (e.g., Active Directory), и т.д.

  3. Основные этапы / Рабочие потоки (Workstreams)

  (Это ключевая часть. Здесь мы разбиваем весь проект на крупные блоки работ).

   * Этап 1: Интеграция с поставщиком учетных записей (Active Directory).
       * Тип работы: Интеграция.
       * Результат: Заполненный "Шаблон для интеграции" для подключения к AD по протоколу LDAP или через API.

   * Этап 2: Разработка базового сервиса аутентификации.
       * Тип работы: Разработка внутренней фичи (новый микросервис).
       * Результат: Заполненный "Шаблон для новой фичи", описывающий API самого сервиса Auth (например, эндпоинты /login, /token, /validate).
         Баз данных и прочего он не касается.

   * Этап 3: Разработка UI для управления пользователями и ролями.
       * Тип работы: Разработка UI-фичи.
       * Результат: Заполненный "Шаблон для новой фичи" для админ-панели, где можно будет создавать пользователей, назначать им роли и т.д.

   * Этап 4: Автоматизация создания "проектов" и заявок.
       * Тип работы: Оркестрация процессов (как в вашем предыдущем вопросе).
       * Результат: Заполненный "Шаблон для новой фичи" (для UI) и несколько "Шаблонов для интеграции" (для API Service Desk, API GitLab и
         т.д.).
=================================
===========================
Мыслительный алгоритм техлида при чтении спецификации

  Представьте, что техлид надевает две разные "шляпы" по очереди.

  Проход 1: "Шляпа пессимиста" (Анализ рисков — ваш подход)

  На этом этапе техлид читает документ и задает себе один главный вопрос: "Что может пойти не так или занять вечность?". Он ищет "белые
  пятна" и зависимости.

   * Вопрос 1: "Что нам нужно от других людей/команд?" (Внешние зависимости)
       * Он смотрит на разделы 2 и 3.
       * Находит: "Нужно согласование с ИБ", "Нужно сгенерировать сертификат", "Нужно, чтобы команда Х зарегистрировала наш сертификат".
       * Результат: Немедленно создает в Jira задачи типа [Admin] или [Infra].
           * Task: [Admin] Согласовать сетевые доступы с ИБ.
           * Task: [Infra] Развернуть proxy-сервер.
           * Вывод: Эти задачи — самые долгие, их нужно запустить первыми, чтобы они выполнялись параллельно с разработкой.

   * Вопрос 2: "В чем мы не уверены?" (Техническая неопределенность)
       * Он смотрит на раздел 3.1 и 3.2.
       * Находит: "Используется протокол gRPC, с которым команда еще не работала" или "Механизм аутентификации — проприетарный".
       * Результат: Создает исследовательские задачи типа [Spike].
           * Spike: Исследовать подключение к gRPC-сервису и сгенерировать клиент.
           * Вывод: Эти задачи нужно сделать до основной разработки, чтобы понять, как вообще подступиться к технологии.

   * Вопрос 3: "Что мешает разработчику начать писать код прямо сейчас?" (Блокеры разработки)
       * Он смотрит на раздел 5.
       * Находит: "Примеры ответов API отсутствуют".
       * Результат: Создает блокирующую задачу для аналитика.
           * Task: [АНАЛИТИКА] Добавить в спецификацию моки ответов от API.
           * Вывод: Без этого разработчик не сможет написать код, который можно проверить.

  Проход 2: "Шляпа архитектора" (Декомпозиция работы)

  После того как все риски и "дыры" выявлены и по ним созданы задачи, техлид делает второй проход. Теперь он задает вопрос: "Из каких 
  технических частей состоит эта фича?". Здесь он использует ту самую классификацию, которую мы обсуждали.

   * Категория А: Задачи на основную бизнес-логику
       * На основе разделов 4 и 5.
       * Мысль: "Какое ядро функциональности мы можем написать и протестировать в полной изоляции, используя моки?"
       * Задачи: Реализовать сервис расчета, Написать маппер данных, Покрыть логику Unit-тестами.

   * Категория Б: Задачи на интеграцию ("клей")
       * На основе разделов 3.2 и 2.1.
       * Мысль: "Какой код нам нужен, чтобы соединить нашу бизнес-логику с реальным миром?"
       * Задачи: Настроить HTTP-клиент с mTLS сертификатом, Добавить использование proxy в клиент, Подключить реальные креды из vault.

   * Категория В: Задачи на эксплуатацию ("броня")
       * На основе раздела 6.
       * Мысль: "Как сделать так, чтобы этот код был надежным и мы знали, что с ним происходит?"
       * Задачи: Реализовать механизм retry, Добавить метрики (счетчики, гистограммы), Настроить детальное логирование.

  Итог

  Ваш подход — это первый, самый важный шаг техлида. Он позволяет выявить все, что может затормозить проект. А моя предыдущая классификация —
  это второй шаг, который структурирует саму разработку.

   * Этап 5: Миграция первого пилотного приложения на новую систему Auth.
       * Тип работы: Интеграция.
       * Результат: Заполненный "Шаблон для интеграции", описывающий, как пилотное приложение будет "общаться" с нашим новым сервисом Auth.
--------------------
Мета-чек-лист: Ключевые вопросы для анализа любой задачи

  1. Цель и Контекст ("Зачем?" и "Кто?")
   * Какую бизнес-проблему мы решаем?
   * Кто является источником данных или участником процесса?
   * С кем из людей нам нужно общаться для получения информации?

  2. Среды и Доступность ("Где это находится?")
   * Существует ли система на PROD и TEST-средах? (ваш пункт)
   * Где она расположена в сети и каков до нее маршрут (прямой, через прокси)?

  3. Доступы и Разрешения ("Как туда попасть?")
   * Есть ли у нас уже доступ к системе, или его нужно получать? (ваш пункт)
   * Если доступа нет, то каков процесс его получения (технический и бюрократический)? (ваш пункт)
   * Нужно ли согласовывать это взаимодействие с кем-то (отдел ИБ, архитекторы)? (ваш пункт)

  4. Данные и Логика ("Что мы делаем?")
   * В каком виде мы получаем данные (технология, формат)?
   * Есть ли у нас примеры этих данных (моки), чтобы начать разработку? (ваш пункт)
   * Что конкретно мы должны сделать с этими данными после получения (наша бизнес-логика)? (ваш пункт)

  5. Эксплуатация и Надежность ("Как сделать, чтобы это работало всегда?")
   * Каковы "правила игры" при работе с системой в промышленной среде (лимиты, политика повторных запросов)?
   * Как мы будем следить, что интеграция работает, и как будем разбирать проблемы (метрики и аудит)?
---------------------
Распределение ролей и ответственности (в виде списка)

  1. Стратегия и Планирование
   * Создание бизнес-целей (Эпики в Jira):
       * Основная роль: Владелец Продукта (PO)
       * Участвующие роли: Техлид, Аналитик
   * Проектирование концептуальной архитектуры (внешние интеграции, схемы в КАФО):
       * Основная роль: Архитектор концептуальной архитектуры
       * Участвующие роли: Владелец Продукта, Аналитик
   * Проектирование Solution-архитектуры (внутреннее устройство сервиса):
       * Основная роль: Solution Architect / Техлид
       * Участвующие роли: DevOps-инженер, Разработчики

  2. Анализ и Проектирование
   * Проведение анализа, заполнение шаблонов:
       * Основная роль: Аналитик ЭД(Вся активнось с внешними источниками+ рекомендации для агента), ИВ(Оля)
      * Проектирование БД(Кирилл)
       * Участвующие роли: Техлид, Команда источника
   * Дизайн UI/UX (создание макетов):
       * Основная роль: UI/UX Дизайнер
       * Участвующие роли: Аналитик, Владелец Продукта

  3. Разработка и Качество
   * Декомпозиция и создание задач на разработку:
       * Основная роль: Техлид
       * Участвующие роли: Разработчики, Аналитик
   * Написание кода и Unit-тестов:
       * Основная роль: Разработчик
       * Участвующие роли: Техлид (для Code Review)
   * Проведение Code Review:
       * Основная роль: Техлид / Другой Разработчик
   * Ручное и автоматизированное тестирование:
       * Основная роль: QA-инженер
       * Участвующие роли: Разработчик, Аналитик
   * Проведение ПСИ (Приемо-сдаточных испытаний):
       * Основная роль: QA-инженер / Владелец Продукта
       * Участвующие роли: Аналитик

  4. Инфраструктура и Доступы
   * Заказ "железа", настройка серверов/ВМ:
       * Основная роль: DevOps-инженер / Системный админ
       * Участвующие роли: Техлид
   * Получение доступов (заявки в ИБ, к системам):
       * Основная роль: Аналитик / Техлид
   * Администрирование серверов (ОС, патчи):
       * Основная роль: Системный администратор (Серега МпР) / DevOps

  5. Релиз и Эксплуатация
   * Настройка CI/CD, мониторинга, логов:
       * Основная роль: DevOps-инженер
       * Участвующие роли: Техлид, Разработчик
   * Подготовка и согласование релиза:
       * Основная роль: Техлид / DevOps-инженер
       * Участвующие роли: Владелец Продукта, QA-инженер
   * Поддержка в PROD, разбор инцидентов:
       * Основная роль: Команда разработки / DevOps (по графику)
---------------------------
 Шаг 2: Декомпозиция самой работы ("Шляпа архитектора")

  На этом этапе техлид перестает думать о том, что может пойти не так, и начинает отвечать на вопрос: "Из каких конкретных технических частей 
  будет состоять наша фича?".

  Он снова смотрит на спецификацию, но теперь уже для того, чтобы спланировать саму разработку. Он мысленно (а затем и в Jira) разделяет всю
  работу на три логические категории.

  Категория А: Задачи на основную бизнес-логику (Ядро функциональности)

  Это "чистый" код, который можно написать и протестировать в полной изоляции, даже не имея никаких доступов.

   * Мысль техлида: "Какой код мы можем написать прямо сейчас, используя только спецификацию и примеры данных (моки)?"
   * На основе: Разделов 4 ("Логика Работы с Данными") и 5 ("Ускорение Разработки").
   * Примеры задач в Jira:
       * Story: [Backend] Реализовать сервис для расчета критерия C-09.
       * Task: Создать DTO (Data Transfer Objects) для ответа от API Системы Х.
       * Task: Написать Unit-тесты для сервиса расчета, используя моки из спецификации.

  Категория Б: Задачи на интеграцию (Технический "клей")

  Это код, который соединяет наше "ядро" с реальным миром. Эти задачи можно взять в работу, когда доступы из Шага 1 будут получены.

   * Мысль техлида: "Какой код нам нужен, чтобы наше 'ядро' смогло реально общаться с внешней системой?"
   * На основе: Разделов 3.2 ("Реквизиты для подключения") и 2.1 ("Сетевое взаимодействие").
   * Примеры задач в Jira:
       * Task: [Backend] Настроить HTTP-клиент с использованием mTLS сертификата из vault.
       * Task: Добавить в конфигурацию клиента использование proxy-сервера.
       * Task: Подключить реальные креды (логин/пароль) из vault для аутентификации.

  Категория В: Задачи на эксплуатацию ("Броня" и "Приборная панель")

  Это код, который делает нашу фичу надежной, наблюдаемой и готовой к работе в промышленной среде.

   * Мысль техлида: "Как сделать этот код отказоустойчивым и как мы узнаем, что с ним что-то не так?"
   * На основе: Раздела 6 ("Эксплуатация и Ограничения").
   * Примеры задач в Jira:
       * Task: [Backend] Реализовать механизм повторных запросов (retry) с экспоненциальной задержкой.
       * Task: [Monitoring] Добавить технические метрики: счетчики успехов/ошибок, гистограмму latency.
       * Task: [Logging] Настроить детальное логирование ключевых шагов интеграции.

  ---

  Итог двух шагов

   * Шаг 1 (Анализ рисков) обеспечивает запуск долгих административных процессов и управление неопределенностью.
   * Шаг 2 (Декомпозиция работы) обеспечивает создание структурированного и понятного бэклога для команды разработки.
-------------------------------
 Шаблон спецификации для новой фичи

  1. Общая информация

   * Название фичи: (Краткое, понятное название, e.g., "Экран модерации расчетов ИЗИ")
   * Ссылка на эпик в Jira: (Ссылка на родительскую задачу)
   * Проблема / Бизнес-цель: (Описать, какую проблему пользователя или бизнеса мы решаем. ЗАЧЕМ мы это делаем? E.g., "Модераторы тратят много
     времени на проверку расчетов, так как у них нет единого интерфейса для просмотра и утверждения. Цель — ускорить процесс модерации в 3
     раза.")
   * Пользовательские роли: (Для КОГО эта фича? E.g., "Модератор", "Администратор")

  2. Функциональные требования в формате User Stories

  (Это основной раздел, описывающий, ЧТО должна делать фича. Лучше всего разбить большую фичу на несколько маленьких историй.)

   * User Story 1: Просмотр списка расчетов
       * Как Модератор, я хочу видеть на экране список всех расчетов, ожидающих модерации, чтобы я мог быстро оценить объем работы.
   * User Story 2: Фильтрация списка
       * Как Модератор, я хочу иметь возможность фильтровать список расчетов по источнику и дате, чтобы я мог найти конкретный расчет.
   * User Story 3: Утверждение/отклонение расчета
       * Как Модератор, я хочу иметь возможность нажать кнопки "Утвердить" или "Отклонить" для каждого расчета, чтобы я мог завершить процесс
         модерации.

  3. Требования к UI/UX (Пользовательский интерфейс)

  (Этот раздел отвечает на вопрос, КАК это должно выглядеть. Он не требует от аналитика быть дизайнером, но требует описать основные
  элементы.)

   * Расположение в интерфейсе: (Где пользователь найдет эту фичу? E.g., "Новый пункт меню 'Модерация' в левой боковой панели.")
   * Основные элементы экрана: (Что пользователь увидит на странице?)
       * Таблица с расчетами. Колонки: ID Источника, Дата расчета, Итоговый балл, Статус.
       * Блок с фильтрами над таблицей: выпадающий список Источник, поле для выбора Даты.
       * В каждой строке таблицы — кнопки Утвердить и Отклонить.
   * Ссылка на макеты/прототипы: (Критически важный пункт!) Ссылка на дизайн в Figma, Balsamiq или даже просто скриншот с нарисованными от руки
     элементами.

  4. Бизнес-логика и правила валидации

  (Здесь описываются конкретные правила и условия.)

   * Кнопка "Утвердить" активна только для расчетов в статусе "Ожидает модерации".
   * При отклонении расчета должно появляться модальное окно с обязательным полем для ввода причины отклонения.
   * Пользователи с ролью "Администратор" видят все расчеты, а "Модератор" — только те, что назначены на его отдел.

  5. Пограничные случаи и обработка ошибок

  (Что будет, если что-то пойдет не так или данных нет?)

   * Пустое состояние: Что показывать, если список расчетов на модерацию пуст? (e.g., "Показывать текст 'Расчетов для модерации нет' и
     картинку.")
   * Ошибка загрузки: Что делать, если не удалось загрузить список с сервера? (e.g., "Показать сообщение об ошибке 'Не удалось загрузить
     данные' и кнопку 'Попробовать снова'.")

  6. Критерии приемки (Acceptance Criteria)

  (Как мы поймем, что фича работает правильно? Формат GIVEN-WHEN-THEN идеален для QA.)

   * Сценарий 1: Успешное утверждение
       * GIVEN: Модератор находится на экране модерации и видит расчет со статусом "Ожидает модерации".
       * WHEN: Он нажимает кнопку "Утвердить".
       * THEN: Статус расчета меняется на "Утвержден", и он пропадает из списка.

  7. Нефункциональные требования

  (Требования к качеству, безопасности, производительности.)

   * Производительность: Список расчетов должен загружаться не дольше 2 секунд.
   * Безопасность: Доступ к этому экрану должен быть только у ролей "Модератор" и "Администратор".
   * Аудит: Каждое действие (утверждение, отклонение) должно записываться в журнал аудита с указанием, какой модератор и когда это сделал.
--------------------
Это отличный и очень важный вопрос, который помогает нам финализировать процесс. Вы все правильно помните, и сейчас мы точно определим место
  тестирования в нашей схеме.

  Короткий ответ: Нет, детальные тест-кейсы в спецификации писать не нужно. Но в спецификации обязательно должен быть раздел "Критерии 
  приемки" (Acceptance Criteria), на основе которого QA-инженер и будет писать свои тест-кейсы.

  Давайте разберем разницу.

  Критерии приемки vs. Тест-кейсы

  Это два разных уровня детализации с разными авторами и целями.

  1. Критерии приемки (Acceptance Criteria)

   * Что это: Высокоуровневые правила, которые описывают, что система должна делать, чтобы фича считалась выполненной. Они отвечают на вопрос:
     "Как мы поймем, что задача решена?".
   * Кто пишет: Аналитик (вместе с Владельцем Продукта). Это неотъемлемая часть спецификации.
   * Формат: GIVEN-WHEN-THEN (Дано-Когда-Тогда), который мы уже используем в шаблоне.
   * Пример (из нашего шаблона):
       * GIVEN: Модератор видит расчет со статусом "Ожидает модерации".
       * WHEN: Он нажимает кнопку "Утвердить".
       * THEN: Статус расчета меняется на "Утвержден".

  2. Тест-кейсы (Test Cases)

   * Что это: Низкоуровневые, пошаговые инструкции для тестировщика, описывающие, как именно проверить функционал. Один критерий приемки
     порождает множество тест-кейсов (позитивных, негативных, на граничные значения).
   * Кто пишет: QA-инженер. Он использует спецификацию и особенно "Критерии приемки" как основу для своей работы. Тест-кейсы обычно пишутся в
     специальных системах (например, TestRail, Zephyr) или просто в Confluence.
   * Формат: Пошаговый скрипт.
   * Пример (на основе критерия приемки выше):
       * Тест-кейс №1 (Позитивный):
           1. Авторизоваться под пользователем moderator_1.
           2. Перейти на страницу /moderation.
           3. Найти в таблице расчет с ID=123. Убедиться, что его статус "Ожидает модерации".
           4. Нажать на кнопку "Утвердить" в строке с ID=123.
           5. Ожидаемый результат: Строка с ID=123 пропадает из таблицы. В базе данных у записи с ID=123 статус изменился на "Утвержден".
       * Тест-кейс №2 (Негативный, проверка прав):
           1. Авторизоваться под пользователем user_simple (у которого нет прав модератора).
           2. Попробовать перейти на страницу /moderation.
           3. Ожидаемый результат: Пользователь видит ошибку "Доступ запрещен" (403).

  Как это выглядит в общем процессе

  Ваш процесс абсолютно верен, давайте просто добавим в него QA-инженера.

   1. ПО создает цель (эпик).
   2. Аналитик создает спецификацию, включая в нее "Критерии приемки".
   3. Техлид декомпозирует спецификацию на задачи для разработчиков.
   4. ПАРАЛЛЕЛЬНО:
       * Разработчики пишут код и юнит-тесты.
       * QA-инженер читает спецификацию и на основе "Критериев приемки" пишет детальные тест-кейсы.
   5. Разработчики заканчивают работу и выкатывают фичу на тестовый стенд.
   6. QA-инженер открывает свои заранее написанные тест-кейсы и по ним проводит тестирование.
   7. ПСИ и релиз на PROD.

  Вывод: Аналитик не пишет детальные инструкции для тестировщика. Он определяет "контракт", по которому фича будет приниматься. А уже
  QA-инженер превращает этот "контракт" в набор исчерпывающих проверок.
------------------
Интеграция — это такая же "фича", просто ее "пользователем" часто является другая система или внутренний процесс. И рисков в ней не меньше,
  а то и больше, потому что проблемы могут быть "тихими" и незаметными сразу.

  Давайте разберем на нашем примере с интеграцией с "Системой Аудит".

  ---

  Критерии приемки (пишет Аналитик в спецификации)

  Аналитик должен добавить в "Шаблон для интеграции" новый раздел, аналогичный тому, что есть в шаблоне для фич.

  Пример Критериев приемки для интеграции с "Системой Аудит":

   * Сценарий 1: Happy Path (инцидент найден)
       * GIVEN: В Системе "Аудит" для источника Source-A существует критичный инцидент.
       * WHEN: Запускается наш сервис расчета индекса ИЗИ.
       * THEN: В нашей базе данных для источника Source-A по критерию "Аудит" сохраняется балл 0 и в поле "доказательство" записывается ID
         этого инцидента.

   * Сценарий 2: Happy Path (инцидентов нет)
       * GIVEN: В Системе "Аудит" для источника Source-B нет критичных инцидентов.
       * WHEN: Запускается наш сервис расчета.
       * THEN: В нашей базе данных для источника Source-B по критерию "Аудит" сохраняется балл 10.

   * Сценарий 3: Обработка ошибки (система-источник недоступна)
       * GIVEN: API Системы "Аудит" не отвечает (возвращает 503 ошибку).
       * WHEN: Запускается наш сервис расчета.
       * THEN: Наш сервис пытается сделать еще 2 повторных запроса (согласно политике retry), и после финальной неудачи в лог записывается
         ошибка уровня ERROR с текстом "Не удалось подключиться к Системе Аудит", а расчет по этому критерию переводится в статус "Ошибка".

  Тест-кейсы (пишет QA-инженер на основе Критериев приемки)

  QA-инженер берет эти критерии и превращает их в детальные технические проверки.

   * Тест-кейс №1.1 (Проверка логики нахождения инцидента):
       1. Поднять мок-сервер, который на запрос GET /api/vincidents?target_system_name=Source-A отдает JSON с критичным инцидентом (из
          спецификации).
       2. Запустить вручную сервис расчета для источника Source-A.
       3. Выполнить SQL-запрос к нашей БД: SELECT score, proof FROM results WHERE source_id='Source-A' AND criterion_id='audit'.
       4. Ожидаемый результат: score равен 0, proof содержит ID инцидента из мок-ответа.

   * Тест-кейс №3.1 (Проверка логики retry при ошибке 503):
       1. Поднять мок-сервер, который на все запросы к GET /api/vincidents отдает HTTP 503 Service Unavailable.
       2. Запустить сервис расчета.
       3. Следить за логами мок-сервера.
       4. Ожидаемый результат: На мок-сервер должно прийти ровно 3 запроса (1 оригинальный + 2 повторных). В логах нашего сервиса должна
          появиться запись об ошибке.
------------------------
Финальный мастер-шаблон для интеграции (с указанием ролей)

  1. Идентификация и Цель
   * С кем консультироваться: Владелец Продукта (PO).
   * Ключевые вопросы:
       * Какую бизнес-проблему мы решаем?
       * Какая система является источником данных?
       * Какие данные нам нужны на концептуальном уровне?
       * С кем со стороны источника велось общение? (контакт для технических вопросов)

  2. Инфраструктура и Окружение
   * С кем консультироваться: Команда источника, DevOps-инженер, Архитекторы (концептуальный и solution).
   * 2.1. Сетевое взаимодействие (Маршрут и Доступы)
       * Ключевые вопросы: Документация архитектуры, Местоположение, Маршрут и Точка подключения, Процесс согласования, Запрос на доступ.
   * 2.2. Тестовые среды
       * Ключевые вопросы: Есть ли у источника тестовый контур? Каковы его реквизиты и ограничения?
   * 2.3. Готовность на PROD
       * Ключевые вопросы: Нужный функционал выведен и стабильно работает в PROD-среде источника?

  3. Доступ к Источнику (Прикладной уровень)
   * С кем консультироваться: Команда источника, Техлид.
   * 3.1. Технология и паттерн интеграции
       * Ключевые вопросы: Какая технология и паттерн используются?
   * 3.2. Реквизиты для подключения (Адреса и Аутентификация)
       * Ключевые вопросы: Адреса/эндпоинты, механизм аутентификации, конкретные креды/ключи.
   * 3.3. Процесс получения доступа (Бюрократия)
       * Ключевые вопросы: Есть ли документация по процессу? Каковы точные шаги?

  4. Логика Работы с Данными
   * С кем консультироваться: Владелец Продукта (для бизнес-смысла), Техлид/Разработчики (для технической реализации логики).
   * Ключевые вопросы:
       * Где находится документация на API / формат сообщений?
       * Какой эндпоинт/топик/таблицу мы используем?
       * Какие параметры запроса нужно передавать / как фильтровать сообщения?
       * Какие поля из ответа/сообщения нам нужны и какую логику к ним применить?
       * Каков финальный результат вычисления?

  5. Критерии приемки (Acceptance Criteria)
   * С кем консультироваться: Владелец Продукта, QA-инженер.
   * Ключевые вопросы:
       * Как мы поймем, что интеграция работает корректно в основном сценарии (happy path)?
       * Как система должна себя вести в случае ожидаемых проблем (e.g., нет данных)?
       * Как система должна обрабатывать технические сбои (e.g., недоступность)?
   * Формат: Рекомендуется использовать GIVEN-WHEN-THEN.

  6. Примеры данных для разработки (моки)
   * С кем консультироваться: Команда источника.
   * Ключевые вопросы:
       * Как выглядят примеры ответов/сообщений для разных сценариев (успех, ошибка, пустой ответ)?

  7. Эксплуатация и Ограничения
   * С кем консультироваться: Команда источника (про лимиты), Техлид и DevOps-инженер (про метрики и ретраи).
   * 7.1. Ограничения на стороне источника
       * Ключевые вопросы: Есть ли rate limits? Какова политика retry?
   * 7.2. Метрики и Аудит
       * Ключевые вопросы: Какие технические метрики нужно собирать? Какие данные нужны для аудита?

  ---
  Теперь шаблон не только говорит аналитику, что нужно узнать, но и к кому пойти, чтобы это узнать. Это делает процесс еще более понятным и
  снижает время на "поиск нужного человека".
-----------------Встречи в рамках двухнедельного спринта

  Всего у вас будет 4 обязательные встречи (церемонии Scrum) и одна очень рекомендуемая.

  1. Планирование спринта (Sprint Planning)

   * Когда: В самом начале спринта (например, в понедельник утром, раз в две недели).
   * Длительность: 2-3 часа.
   * Участники: Вся команда (Владелец Продукта, Техлид, все Разработчики, QA-инженер, Аналитик, DevOps-инженер).
   * Цель:
       1. Владелец Продукта (PO) представляет самые важные задачи из бэклога.
       2. Команда обсуждает эти задачи, задает вопросы аналитику и техлиду.
       3. Команда решает, какой объем работы она реально может взять на ближайшие две недели (формируется "бэклог спринта").
       4. Результат: У команды есть четкая цель на спринт и список задач, которые она обязалась выполнить.

  2. Ежедневный стендап (Daily Stand-up)

   * Когда: Каждый день в одно и то же время (например, в 11:00).
   * Длительность: Строго 15 минут.
   * Участники: Техническая команда (Техлид, Разработчики, QA, DevOps, Аналитик). PO может присутствовать, но не отчитывается.
   * Цель: Быстрая синхронизация, а не решение проблем. Каждый участник отвечает на 3 вопроса:
       1. Что я делал вчера, чтобы помочь команде достичь цели спринта?
       2. Что я буду делать сегодня?
       3. Какие у меня есть проблемы или блокеры?
   * Все обсуждения выносятся за рамки стендапа и решаются после него только с нужными людьми.

  3. Груминг Бэклога (Backlog Refinement/Grooming)
  (Это не официальная церемония Scrum, но это лучшая практика, без которой не обходится почти ни одна команда).

   * Когда: Раз в неделю, обычно в середине спринта (например, в пятницу первой недели).
   * Длительность: 1 час.
   * Участники: Вся команда.
   * Цель: Подготовить задачи для следующего спринта.
       1. PO и аналитик показывают "черновики" будущих задач и спецификаций.
       2. Команда задает первые вопросы, чтобы аналитик мог доработать спецификацию.
       3. Команда дает предварительную, "грубую" оценку сложности (например, по размерам футболок: S, M, L, XL).
   * Это делает следующее Планирование спринта намного быстрее и эффективнее.

  4. Обзор спринта (Sprint Review / Демо)

   * Когда: В конце спринта (например, в пятницу второй недели, перед Ретроспективой).
   * Длительность: 1 час.
   * Участники: Вся команда + приглашенные стейкхолдеры (руководство, пользователи, другие команды).
   * Цель: Показать работающий продукт.
       1. Команда демонстрирует то, что было сделано за спринт. Это живой показ, а не презентация.
       2. Стейкхолдеры дают обратную связь.
       3. PO подводит итоги, что было сделано, а что нет.

  5. Ретроспектива спринта (Sprint Retrospective)

   * Когда: В самом конце спринта, после Демо.
   * Длительность: 1-1.5 часа.
   * Участники: Только команда разработки. Никаких менеджеров и стейкхолдеров со стороны. Это безопасное пространство для команды.
   * Цель: Обсудить процесс работы, а не продукт. Команда отвечает на 3 вопроса:
       1. Что у нас получилось хорошо в этом спринте?
       2. Что можно было бы улучшить?
       3. Какие одно-два конкретных действия мы предпримем в следующем спринте, чтобы стать лучше?
   * Результат: План улучшений на следующий спринт.

  ---

  Расписание встреч на двухнедельный спринт (в виде списка)

  Неделя 1

   * Понедельник (утро):
       * Планирование спринта (длительность 2-3 часа)

   * Каждый день (Вторник - Пятница):
       * Ежедневный стендап (длительность 15 минут)

   * Пятница (середина дня):
       * Груминг Бэклога (длительность 1 час)

  Неделя 2

   * Каждый день (Понедельник - Пятница):
       * Ежедневный стендап (длительность 15 минут)

   * Пятница (конец дня):
       * Обзор спринта / Демо (длительность 1 час)
       * Ретроспектива (длительность 1-1.5 часа)

 Здравствуйте.

  Я с большим интересом ознакомился с вакансией Tech Lead и хотел бы предложить свою кандидатуру. Уверен, что мой практический опыт в проектировании и
  руководстве разработкой сложных AI-систем будет полезен вашей команде.

  В основной работе я совмещаю роли Product Owner и Team/Tech Lead, руковожу внедрением AI-агента. Он рассчитывает «индекс зрелости» источника для загрузки
  данных в корпоративную платформу (КАП). В мои задачи входит: проектирование solution-архитектуры, анализ и построение интеграций для получения данных 
  агентом, декомпозиция задач и контроль полного цикла релиза (ПСИ, прод). Небольшая команда и сжатые сроки требуют активного участия на всех этапах.

  Параллельно, для глубокого изучения AI-систем, в личное время я с нуля создал pet-проект: low-code платформу для AI-автоматизаций на React (Next.js). Она
  имеет drag-and-drop редактор, мульти-командный доступ и хранилище секретов. Ключевой модуль — Dispatcher, AI-оркестратор с Function Calling для вызова
  других воркфлоу. Архитектура расширяется через MCP-сервисы: Ingestion API, Email (IMAP) и RAG-сервис на pgvector.
