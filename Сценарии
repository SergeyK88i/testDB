Финальный мастер-шаблон (версия с полными подсказками)

  1. Идентификация и Цель
   * Ключевые вопросы:
       * Какую бизнес-проблему мы решаем?
       * Какая система является источником данных?
       * Какие данные нам нужны на концептуальном уровне?
       * С кем со стороны источника велось общение? (контакт для технических вопросов)

  2. Инфраструктура и Окружение

   * 2.1. Сетевое взаимодействие (Маршрут и Доступы)
       * Ключевые вопросы:
           * Документация архитектуры: Отражена ли интеграция в официальной архитектурной схеме проекта?
           * Местоположение: В каких сегментах сети находятся наш сервис и целевая система?
           * Маршрут и Точка подключения: Исходя из местоположения, каким будет маршрут (прямой, через proxy/gateway)? Каким будет итоговый
             адрес для подключения нашего сервиса?
           * Процесс согласования: Требуется ли формальное согласование этого сетевого взаимодействия (например, с отделом ИБ)?
           * Запрос на доступ: Если да, что именно нужно указать в заявке на открытие доступов (IP источника, IP назначения, порт)?

   * 2.2. Тестовые среды
       * Ключевые вопросы:
           * Есть ли у источника тестовый контур? Каковы его реквизиты и ограничения?

   * 2.3. Готовность на PROD
       * Ключевые вопросы:
           * Нужный функционал выведен и стабильно работает в PROD-среде источника?

  3. Доступ к Источнику (Прикладной уровень)

   * 3.1. Технология и паттерн интеграции
       * Ключевые вопросы:
           * Какая технология и паттерн используются (e.g., REST, gRPC, Kafka, DB Connection)?

   * 3.2. Реквизиты для подключения (Адреса и Аутентификация)
       * Ключевые вопросы (адаптируются под п. 3.1):
           * Каковы адреса/эндпоинты для подключения?
           * Какой механизм аутентификации используется?
           * Какие конкретно креды/ключи/сертификаты нужны?
       * Подсказка/Примеры:
           * Адреса:
               * Для REST: https://api.some-service.com/v1/
               * Для Kafka: kafka1.corp.local:9092
               * Для БД: postgres-db.prod.local:5432
           * Механизмы аутентификации:
               * Bearer Token, API Key, Basic Auth, mTLS, SASL/SCRAM, AD ТУЗ (Kerberos/NTLM)
           * Креды/ключи (конкретные секреты):
               * Для API Key: ABC-123-XYZ-456
               * Для mTLS: Указание на файлы client.crt, client.key и их Common Name (CN).
               * Для AD ТУЗ: Пара логин/пароль. Например: login: srv_myapp_prod, password: (хранится в vault).

   * 3.3. Процесс получения доступа (Бюрократия)
       * Ключевые вопросы:
           * Есть ли документация, описывающая процесс получения доступа? (e.g., статья в Confluence, регламент)
           * Каковы точные шаги для получения кредов/ключей/сертификатов, описанных в п. 3.2? (e.g., "Подать заявку в Service Desk по шаблону
             X")

  4. Логика Работы с Данными
   * Ключевые вопросы:
       * Где находится документация на API / формат сообщений?
       * Какой эндпоинт/топик/таблицу мы используем?
       * Какие параметры запроса нужно передавать / как фильтровать сообщения?
       * Какие поля из ответа/сообщения нам нужны и какую логику к ним применить?
       * Каков финальный результат вычисления?

  5. Ускорение Разработки и Критерии Успеха
   * Ключевые вопросы:
       * Как выглядят примеры ответов/сообщений (успех, ошибка, пустой ответ)?
       * Как мы однозначно поймем, что задача выполнена корректно?

  Обновленный раздел 6

  6. Эксплуатация и Ограничения

   * 6.1. Ограничения на стороне источника
       * Ключевые вопросы:
           * Есть ли ограничения на частоту запросов (rate limits)?
           * Какой должна быть наша стратегия повторных запросов (retry policy)?

   * 6.2. Метрики и Аудит
       * Ключевые вопросы:
           * Технические метрики: Какие технические метрики нужно собирать для мониторинга здоровья интеграции? (e.g., количество 
             успехов/ошибок, время выполнения)
           * Данные для аудита: Какие данные о результате вычисления и "доказательства" нужно сохранять для последующего аудита и разбора?
             (e.g., "Сохранять итоговый балл, ID проверенной страницы в Confluence, время проверки")

  ---

  Пример заполнения для нового пункта 6.2

   * Технические метрики:
       * счетчик успешных проверок по критерию
       * счетчик ошибок по критерию и типу (сетевая, ошибка парсинга, нет данных)
       * гистограмма длительности выполнения проверки (latency)
   * Данные для аудита:
       * ID источника
       * ID критерия
       * итоговый балл
       * время проверки (timestamp)
       * ключевое "доказательство" (например, ID найденной страницы в Confluence или конкретное значение, полученное из API, которое повлияло 
         на решение)

1. Технические метрики (для инженеров)

  Цель: Следить за "здоровьем" и производительностью интеграции в реальном времени. Отвечают на вопрос: "Все ли работает как надо?". Эти
  данные обычно отправляются в системы мониторинга (например, Prometheus, Grafana).

   * `счетчик успешных проверок по критерию`
       * Что это: Простая цифра, которая увеличивается на 1 каждый раз, когда мы успешно рассчитали один критерий для одного источника.
       * Зачем это нужно: Если мы видим, что этот счетчик перестал расти, значит, наш процесс сломался или остановился. Мы можем настроить
         алерт: "Если за час не было ни одной успешной проверки, прислать уведомление в #alerts".

   * `счетчик ошибок по критерию и типу (сетевая, ошибка парсинга, нет данных)`
       * Что это: Счетчик, который срабатывает при ошибке. Важно, что мы помечаем его "типом" ошибки.
       * Зачем это нужно: Это главный инструмент для диагностики.
           * Резко вырос счетчик сетевых ошибок? Значит, проблема со связью до системы-источника, нужно проверить сеть.
           * Растет счетчик ошибок парсинга? Значит, источник мог поменять формат ответа своего API, и нам нужно адаптировать наш код.
           * Растет счетчик "нет данных"? Значит, интеграция работает, но мы не находим нужную информацию, возможно, ее удалили или
             переместили.

   * `гистограмма длительности выполнения проверки (latency)`
       * Что это: Метрика, которая измеряет, сколько миллисекунд или секунд уходит на одну проверку. Гистограмма позволяет видеть не просто
         среднее время, а распределение (e.g., 90% запросов выполняются за 200мс, а 10% — за 2 секунды).
       * Зачем это нужно: Для отслеживания производительности. Если мы видим, что время проверки постепенно растет, это сигнал, что
         система-источник стала медленнее или наш алгоритм неэффективен. Это помогает обеспечивать соблюдение нефункциональных требований
         ("система должна быть быстрой").

  ---

  2. Данные для аудита (для бизнес-пользователей и владельцев источников)

  Цель: Обеспечить полную прозрачность и доказуемость расчетов. Отвечают на вопрос: "Почему для этого источника получился именно такой
  балл?". Эти данные обычно сохраняются в базу данных или лог-файлы на длительный срок.

   * `ID источника`, `ID критерия`, `итоговый балл`, `время проверки (timestamp)`
       * Что это: Базовая информация: кто, что проверяли, какой результат получили и когда.
       * Зачем это нужно: Это основа для любого отчета или расследования. Позволяет делать запросы вроде "Покажи все расчеты для 'Источника А'
         за последний месяц".

   * `ключевое "доказательство"`
       * Что это: Это самая важная часть для аудита. Это конкретная улика или факт, на основе которого был сделан вывод.
       * Зачем это нужно: Это ответ на вопрос "На каком основании?".
           * Пример 1: Критерий — "Наличие документации в Confluence". Расчет успешен, балл = 10. "Доказательством" будет page_id=54321
             найденной страницы. Если владелец источника спросит "Почему 10?", мы ответим: "Потому что мы нашли вот эту страницу: [ссылка]".
           * Пример 2: Критерий — "Отсутствие критичных инцидентов". Расчет провален, балл = 0. "Доказательством" будет incident_id='INC-98765'
             найденного инцидента. Мы можем сказать: "Балл снижен из-за этого конкретного инцидента, разберитесь с ним".


-------------------
Цель мониторинга — в реальном времени, с помощью дашбордов (в Grafana), понимать, что происходит с вашей системой. Это приборная панель
  вашего сервиса.

  Принято использовать стандартный набор метрик, который описывает три ключевых аспекта работы любого сервиса (метод RED: Rate, Errors,
  Duration).

  Вот что должно быть в вашем мониторинге для каждой интеграции:

  ---

  1. Rate (Интенсивность) — "Как часто мы это делаем?"

  Эта метрика показывает нагрузку на вашу систему.

   * Название метрики: integration_runs_total
   * Тип: Counter (счетчик, который только увеличивается)
   * Зачем нужна:
       * Показывает, сколько всего проверок было запущено.
       * Если график rate(integration_runs_total[5m]) (скорость запусков за 5 минут) падает до нуля, это значит, что ваш сервис перестал
         запускать проверки. Это повод для алерта.
       * Резкий всплеск может говорить о том, что проверки запускаются по ошибке слишком часто.
   * Важные метки/лейблы: criterion_id (чтобы видеть интенсивность по каждому критерию отдельно).

  2. Errors (Ошибки) — "Как много у нас проблем?"

  Это самая важная метрика для оценки здоровья системы.

   * Название метрики: integration_errors_total
   * Тип: Counter
   * Зачем нужна:
       * Показывает общее количество ошибок. Если это число начинает расти — это главный сигнал о проблеме и повод для срочного алерта.
       * Позволяет считать уровень ошибок (Error Rate) = количество ошибок / общее количество запусков.
   * Важные метки/лейблы:
       * criterion_id: Позволяет понять, какой именно критерий "сломался".
       * error_type: Критически важная метка для диагностики. Значения могут быть:
           * network: Не удалось подключиться к источнику.
           * auth: Ошибка аутентификации (неверный токен, пароль).
           * parsing: Не удалось разобрать ответ от API (источник поменял формат).
           * business_logic: Ошибка в нашей внутренней логике расчета.

  Как это используется: На дашборде в Grafana вы строите график скорости роста ошибок, сгруппированный по error_type. Если вы видите всплеск
  ошибок типа auth для критерия C-05, вы точно знаете, что у вас, скорее всего, "протух" токен для этой конкретной интеграции.

  3. Duration (Длительность) — "Как быстро мы работаем?"

  Эта метрика отслеживает производительность и "тормоза".

   * Название метрики: integration_duration_seconds
   * Тип: Histogram или Summary
   * Зачем нужна:
       * Показывает, сколько времени занимает расчет одного критерия.
       * Помогает отслеживать деградацию производительности. Если среднее время или 99-й перцентиль (самые медленные запросы) начинают расти,
         это значит, что либо источник стал медленнее отвечать, либо наш код стал менее эффективным.
       * Позволяет настроить алерт: "Если 95-й перцентиль времени ответа больше 5 секунд, прислать уведомление".
   * Важные метки/лейблы: criterion_id.

  ---

  Итог для дашборда

  Имея эти три типа метрик, вы можете создать в Grafana полный дашборд для мониторинга ваших интеграций, где по каждому критерию будет видно:
   1. График интенсивности запусков.
   2. График количества и типа ошибок.
   3. График времени выполнения (среднее и 99-й перцентиль).

  Это позволяет вам перейти от реактивного подхода ("пользователь сообщил о проблеме") к проактивному ("наш дашборд показывает аномалию,
  давайте исправим ее до того, как пользователи это заметят").

=============================================================

Да, вы можете начать декомпозицию и разработку раньше. Для этого нужно разделить наш шаблон на два блока: абсолютный минимум для старта и
  все остальное, что можно получить параллельно.

  ---

  Блок 1: Абсолютный минимум для старта разработки (пишем код на моках)

  Это тот набор информации, без которого разработчик в принципе не может начать писать код, даже в изоляции от реальной системы. Как только
  аналитик заполнил эти пункты, техлид может создавать первые задачи.

  Супер обязательные пункты:

   1. Раздел 1. Идентификация и Цель (полностью): Нужно понимать бизнес-задачу.
   2. Пункт 3.1. Технология и паттерн интеграции: Принципиально важно знать, это REST или Kafka, так как от этого зависит вся архитектура кода.
   3. Раздел 4. Логика Работы с Данными (частично, но критично):
       * Структура данных: Какие поля есть в ответе/сообщении.
       * Основная логика: Что с этими полями делать.
       * Ссылка на документацию может подождать, если есть примеры.
   4. Пункт 5. Ускорение Разработки (только примеры ответов/сообщений): Это ключ к параллельной разработке. Имея на руках пример JSON-ответа,
      разработчик может создать классы, написать логику и полностью покрыть ее юнит-тестами, не имея реального доступа к системе.

  Что можно делать с этим блоком?
  Как только эти пункты заполнены, техлид может ставить задачи вида:
   * "Создать модель данных (DTO) для ответа от Системы Х".
   * "Реализовать сервис для обработки данных от Системы Х (на входе мок, на выходе результат)".
   * "Написать юнит-тесты для сервиса обработки".

  ---

  Блок 2: Необходимо для реального подключения и вывода в PROD (заполняется параллельно)

  Эти пункты не блокируют написание основной бизнес-логики, но абсолютно необходимы для того, чтобы интеграция заработала по-настоящему.
  Аналитик может продолжать "добывать" эту информацию, пока разработчики пишут код на основе данных из Блока 1.

  Пункты, которые могут подождать (но их получение нужно запустить как можно раньше):

   1. Раздел 2. Инфраструктура и Окружение (полностью): Все вопросы про сеть, доступы, стенды. Это часто самые долгие процессы, их нужно
      запускать в параллель.
   2. Раздел 3 (кроме п. 3.1): Все, что касается реальных адресов, реквизитов и бюрократии по получению доступов.
   3. Раздел 6. Эксплуатация и Ограничения (полностью): Ретраи, метрики, лимиты. Эту "обвязку" можно добавить к уже написанному коду основной
      логики.
   4. Критерии успеха из Раздела 5: Их можно финализировать чуть позже.

  Итог: Стратегия параллельной работы

   1. Аналитик в первую очередь фокусируется на получении информации для Блока 1.
   2. Как только Блок 1 готов, он передает его техлиду. Разработка начинается.
   3. Параллельно аналитик (или техлид) запускает все процессы по получению информации и доступов для Блока 2 (подает заявки в ИБ, запрашивает
      креды и т.д.).
   4. Когда разработчик заканчивает код на моках, в идеале, доступы из Блока 2 уже получены. Остается только подставить реальные адреса и креды,
      дописать логику обработки ошибок, ретраев, метрик и провести интеграционное тестирование.
